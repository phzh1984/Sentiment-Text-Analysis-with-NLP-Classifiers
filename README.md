# Sentiment-Text-Analysis-with-NLP-Classifiers

Overview

This repository analyzes a dataset of tweets related to the Coronavirus pandemic, along with manual annotations for text classification. The dataset was collected from Twitter, and each tweet has been labeled to categorize its content. In this project, we utilize natural language processing (NLP) models, specifically BERT (Bidirectional Encoder Representations from Transformers) and Roberta (A Robustly Optimized BERT Pretraining Approach), to perform text classification on this data.

Dataset Information

The dataset consists of the following columns:

Location: The location of the user who posted the tweet.

Tweet At: The timestamp of when the tweet was posted.

Original Tweet: The text of the tweet.

Label: The label assigned to the tweet based on its content. This label has been manually assigned and represents a categorization of the tweet's topic or sentiment.

Purpose

The main objective of this project is to perform text classification on the Coronavirus-related tweets using advanced NLP models. By training and evaluating models like BERT and RoBERTa, we aim to categorize the tweets into relevant classes, which can be useful for various purposes such as sentiment analysis, topic identification, and understanding public opinion during the pandemic.

NLP Models Used

We have employed two prominent NLP models for text classification:

BERT (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based model that has achieved state-of-the-art results in various NLP tasks. It is known for its bidirectional context understanding and contextual embeddings, making it a powerful choice for text classification.

RoBERTa (A Robustly Optimized BERT Pretraining Approach): RoBERTa is an optimized version of BERT, designed to further enhance performance. It leverages larger batch sizes, longer training times, and other optimizations to achieve superior results in NLP tasks.
